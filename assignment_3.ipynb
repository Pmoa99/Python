{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction to Programming\n",
    "## Foundations - Assignment 3\n",
    "\n",
    "- [Prime factor decomposition](#decomposition)\n",
    "\n",
    "- [Merging dictionaries](#merging)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains 2 exercises. The second exercise was partially solved during lab session 2. Complete these 2 exercises as part of your third assignment, due on Sunday September 26th at midnight. Please return your solutions in jupyter notebook form by email at nbertani@ucp.pt by the deadline. These exercises are graded on effort: non-empty submissions receive full credit. Note that 3 datacamp chapters are also part of assignment 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"decomposition\"></a>\n",
    "### Prime factor decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prime factor decomposition consists in writing a natural number (positive integer) greater than 1 as a product of prime numbers. For instance, the prime factor decomposition of 9 is $3 * 3$, of 22 it is $2 * 11$, and of 252 it is $2 * 2 * 3 * 3 * 7 = 2^2 * 3^2 * 7$.\n",
    "\n",
    "To factorize a number, take the following steps.\n",
    "\n",
    "- Consider a natural number greater than 1.\n",
    "\n",
    "- Find the smallest prime number by which you can divide this number exactly (the result or quotient of the division is an integer, with no remainder). Store the prime number that met the condition: this is your first prime factor.\n",
    "\n",
    "- Take the quotient (the result) of the division above: \n",
    "\n",
    "    - If the quotient is one, you are done.\n",
    "    \n",
    "    - If the quotient is greater than one, repeat the previous step: find the next factor, store it, and then consider the new quotient. In particular, you want to do the following:\n",
    "    \n",
    "        - If it is possible, divide again the quotient by the same prime number you used in the previous step.\n",
    "\n",
    "        - When you cannot divide exactly by the previous factor, divide it by the next possible prime number. This means that you need to find the smallest prime number that is greater than your last used factor and that divides exactly your quotient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program that performs factor decomposition and outputs a list of 2-element tuples to summarize the results. The list must have as many entries as the number of different prime numbers used in the decomposition (i.e. the number of factors). Each entry of the list is a 2-tuple where the first element records what factor has been used and the second records how many times this factor has been used.\n",
    "\n",
    "As an example of output, consider the decomposition of $727, \\, 776 = 2^5 * 3^2 * 7 * 19 ^ 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2, 2, 2, 2, 3, 3, 7, 19, 19], 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prime_factors(n):\n",
    "    i = 2\n",
    "    fact = []\n",
    "    count = 1\n",
    "    while i * i <= n:\n",
    "        if n % i:\n",
    "            i += 1\n",
    "        else:\n",
    "            n //= i\n",
    "            fact.append(i)\n",
    "            count += 1\n",
    "    if n > 1:\n",
    "        fact.append(n)\n",
    "     \n",
    "    return fact , count\n",
    "\n",
    "\n",
    "prime_factors(727776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 ** 5 * 3 ** 2 * 7 * 19 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_factor_decomposition(2 ** 5 * 3 ** 2 * 7 * 19 ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check whether your prime factor decomposition is correct [here](https://www.calculatorsoup.com/calculators/math/prime-factors.php)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "\n",
    "- To create your output, initialize an empty list. Then, create a variable to store your possible divisor, which you can initialize to 2 (the first possible prime divisor). Use a counter to keep track of how many times you use a given divisor. Before you move on to the next divisor, if you have used a given divisor at least once, append the tuple of its value and its counter to the output.\n",
    "\n",
    "- Start with the smallest prime (which is 2) and, when you can no longer exactly divide by it, iteratively consider larger primes (3, 5, 7, etc). To find the next prime divisor, you can simply consider iteratively all numbers larger than your last factor (3, 4, 5, 6, 7, etc). No non-prime number will be a factor.\n",
    "\n",
    "- The simplest check on your code is that the number 2 must be in the factors whenever you are decomposing an even number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"merging\"></a>\n",
    "### Merging dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries and the JSON language are popular format for storing data or observations because of their flexibility. \n",
    "In particular, their flexibility lies in the key:value structure, allowing to store an unspecified number of such pairs. \n",
    "This is very useful when we have observations that have a (small) number of common characteristics and all remaining characteristics are very heterogenous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, data you get from the internet will be in dictionary format for this very reason.\n",
    "However, to perform analyses, you will first need to unify all the common information in these observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do this for the following objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cao2017modelling': {'type': 'article', 'title': 'Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'author': 'Cao, Zheng and Li, Gang and Song, Haiyan', 'journal': 'Annals of Tourism Research', 'volume': 67, 'pages': '1--13', 'year': 2017, 'publisher': 'Elsevier'}, 'ishwaran2011consistency': {'type': 'article', 'author': 'Ishwaran, Hemant and Rao, J Sunil', 'date-added': '2019-09-05 21:53:03 +0200', 'date-modified': '2019-09-05 21:53:14 +0200', 'journal': 'Statistics \\\\& Probability Letters', 'keywords': ['spike-and-slab', 'shrinkage', 'regularization'], 'number': 12, 'pages': '1920--1928', 'publisher': 'Elsevier', 'title': 'Consistency of spike and slab regression', 'volume': 81, 'year': 2011}, 'mccullagh2019generalized': {'type': 'book', 'title': 'Generalized linear models', 'author': 'McCullagh, Peter and Nelder, John A', 'year': 1983, 'publisher': 'Routledge'}}\n",
      "{'friedman2001elements': {'type': 'book', 'title': 'The elements of statistical learning', 'author': 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'volume': 1, 'number': 10, 'year': 2001, 'publisher': 'Springer series in statistics New York'}}\n",
      "{'FanLv2008sure': {'type': 'article', 'author': 'Fan, Jianqing and Lv, Jinchi', 'journal': 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)', 'keywords': ['Adaptive lasso', 'Dantzig selector', 'Dimensionality reduction', 'Oracle estimator', 'Sure independence screening'], 'number': 5, 'pages': 849, 'title': 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.', 'volume': 70, 'year': 2008}}\n"
     ]
    }
   ],
   "source": [
    "entries = {\n",
    "    'cao2017modelling' : {\n",
    "        'type' : 'article',\n",
    "        'title' : 'Modelling the interdependence of tourism demand: The global vector autoregressive approach',\n",
    "        'author' : 'Cao, Zheng and Li, Gang and Song, Haiyan',\n",
    "        'journal' : 'Annals of Tourism Research',\n",
    "        'volume' : 67,\n",
    "        'pages' : '1--13',\n",
    "        'year' : 2017,\n",
    "        'publisher' : 'Elsevier'\n",
    "    },\n",
    "    'ishwaran2011consistency' : {\n",
    "        'type' : 'article',\n",
    "        'author' : 'Ishwaran, Hemant and Rao, J Sunil',\n",
    "        'date-added' : '2019-09-05 21:53:03 +0200',\n",
    "        'date-modified' : '2019-09-05 21:53:14 +0200',\n",
    "        'journal' : 'Statistics \\& Probability Letters',\n",
    "        'keywords' : ['spike-and-slab', 'shrinkage', 'regularization'],\n",
    "        'number' : 12,\n",
    "        'pages' : '1920--1928',\n",
    "        'publisher' : 'Elsevier',\n",
    "        'title' : 'Consistency of spike and slab regression',\n",
    "        'volume' : 81,\n",
    "        'year' : 2011\n",
    "    },\n",
    "    'mccullagh2019generalized' : {\n",
    "        'type' : 'book',\n",
    "        'title' : 'Generalized linear models',\n",
    "        'author': 'McCullagh, Peter and Nelder, John A',\n",
    "        'year': 1983,\n",
    "        'publisher' : 'Routledge'\n",
    "    }\n",
    "}\n",
    "\n",
    "additional_entry = {\n",
    "    'friedman2001elements' : {\n",
    "        'type' : 'book',\n",
    "        'title' : 'The elements of statistical learning',\n",
    "        'author' : 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert',\n",
    "        'volume' : 1,\n",
    "        'number' : 10,\n",
    "        'year' : 2001,\n",
    "        'publisher' : 'Springer series in statistics New York'\n",
    "    }\n",
    "}\n",
    "\n",
    "additional_entry_2 = {\n",
    "    'FanLv2008sure' : {\n",
    "        'type' : 'article',\n",
    "        'author' : 'Fan, Jianqing and Lv, Jinchi',\n",
    "        'journal' : 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)',\n",
    "        'keywords' : ['Adaptive lasso', 'Dantzig selector', 'Dimensionality reduction', 'Oracle estimator', 'Sure independence screening'],\n",
    "        'number' : 5,\n",
    "        'pages' : 849,\n",
    "        'title' : 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.',\n",
    "        'volume' : 70,\n",
    "        'year' : 2008\n",
    "    }    \n",
    "}\n",
    "\n",
    "print(entries)\n",
    "print(additional_entry)\n",
    "print(additional_entry_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the following actions:\n",
    "\n",
    "1. merge all elements in `entries`, `additional_entry` and `additional_entry_2` in a single dictionary called `data`. This has been solved in class.\n",
    "\n",
    "1. create a new dictionary `common_data` to summarize the common information in the elements of `data`. The new dictionary must have keys that are equal to the keys that are common to all dictionaries nested as values in `data`. The associated values of the new dictionary must list all corresponding values from the common nested keys in `data`. Furthermore, in the new dictionary add another key with name `entry name` to store a list of the names of the elements in `data` (i.e. the non-nested keys in the `data` dictionary).\n",
    "\n",
    "1. create two separate dictionaries, one for entries that have `'type' = 'article'` and one for `'type' = 'book'`. Populate each of these new dictionaries as in the previous point. The best way to do this is to create a function that takes as an argument the value of key `type` by which to filter the elements in `data`. A simpler solution is to use the same code twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Merge data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in [entries, additional_entry, additional_entry_2]:\n",
    "    data.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cao2017modelling', 'ishwaran2011consistency', 'mccullagh2019generalized', 'friedman2001elements', 'FanLv2008sure'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cao2017modelling': {'type': 'article', 'title': 'Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'author': 'Cao, Zheng and Li, Gang and Song, Haiyan', 'journal': 'Annals of Tourism Research', 'volume': 67, 'pages': '1--13', 'year': 2017, 'publisher': 'Elsevier'}, 'ishwaran2011consistency': {'type': 'article', 'author': 'Ishwaran, Hemant and Rao, J Sunil', 'date-added': '2019-09-05 21:53:03 +0200', 'date-modified': '2019-09-05 21:53:14 +0200', 'journal': 'Statistics \\\\& Probability Letters', 'keywords': ['spike-and-slab', 'shrinkage', 'regularization'], 'number': 12, 'pages': '1920--1928', 'publisher': 'Elsevier', 'title': 'Consistency of spike and slab regression', 'volume': 81, 'year': 2011}, 'mccullagh2019generalized': {'type': 'book', 'title': 'Generalized linear models', 'author': 'McCullagh, Peter and Nelder, John A', 'year': 1983, 'publisher': 'Routledge'}, 'friedman2001elements': {'type': 'book', 'title': 'The elements of statistical learning', 'author': 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'volume': 1, 'number': 10, 'year': 2001, 'publisher': 'Springer series in statistics New York'}, 'FanLv2008sure': {'type': 'article', 'author': 'Fan, Jianqing and Lv, Jinchi', 'journal': 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)', 'keywords': ['Adaptive lasso', 'Dantzig selector', 'Dimensionality reduction', 'Oracle estimator', 'Sure independence screening'], 'number': 5, 'pages': 849, 'title': 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.', 'volume': 70, 'year': 2008}}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([{'type': 'article', 'title': 'Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'author': 'Cao, Zheng and Li, Gang and Song, Haiyan', 'journal': 'Annals of Tourism Research', 'volume': 67, 'pages': '1--13', 'year': 2017, 'publisher': 'Elsevier'}, {'type': 'article', 'author': 'Ishwaran, Hemant and Rao, J Sunil', 'date-added': '2019-09-05 21:53:03 +0200', 'date-modified': '2019-09-05 21:53:14 +0200', 'journal': 'Statistics \\\\& Probability Letters', 'keywords': ['spike-and-slab', 'shrinkage', 'regularization'], 'number': 12, 'pages': '1920--1928', 'publisher': 'Elsevier', 'title': 'Consistency of spike and slab regression', 'volume': 81, 'year': 2011}, {'type': 'book', 'title': 'Generalized linear models', 'author': 'McCullagh, Peter and Nelder, John A', 'year': 1983, 'publisher': 'Routledge'}, {'type': 'book', 'title': 'The elements of statistical learning', 'author': 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'volume': 1, 'number': 10, 'year': 2001, 'publisher': 'Springer series in statistics New York'}, {'type': 'article', 'author': 'Fan, Jianqing and Lv, Jinchi', 'journal': 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)', 'keywords': ['Adaptive lasso', 'Dantzig selector', 'Dimensionality reduction', 'Oracle estimator', 'Sure independence screening'], 'number': 5, 'pages': 849, 'title': 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.', 'volume': 70, 'year': 2008}])\n"
     ]
    }
   ],
   "source": [
    "print(data.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create the new dictionary with common data**\n",
    "\n",
    "Your output should look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entry name': ['cao2017modelling', 'ishwaran2011consistency', 'mccullagh2019generalized', 'friedman2001elements', 'FanLv2008sure'], 'type': ['article', 'article', 'book', 'book', 'article'], 'title': ['Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'Consistency of spike and slab regression', 'Generalized linear models', 'The elements of statistical learning', 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.'], 'author': ['Cao, Zheng and Li, Gang and Song, Haiyan', 'Ishwaran, Hemant and Rao, J Sunil', 'McCullagh, Peter and Nelder, John A', 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'Fan, Jianqing and Lv, Jinchi'], 'year': [2017, 2011, 1983, 2001, 2008]}\n"
     ]
    }
   ],
   "source": [
    "print(common_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entry name': ['cao2017modelling', 'ishwaran2011consistency', 'mccullagh2019generalized', 'friedman2001elements', 'FanLv2008sure'], 'type': ['article', 'article', 'book', 'book', 'article'], 'title': ['Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'Consistency of spike and slab regression', 'Generalized linear models', 'The elements of statistical learning', 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.'], 'author': ['Cao, Zheng and Li, Gang and Song, Haiyan', 'Ishwaran, Hemant and Rao, J Sunil', 'McCullagh, Peter and Nelder, John A', 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'Fan, Jianqing and Lv, Jinchi'], 'year': [2017, 2011, 1983, 2001, 2008]}\n"
     ]
    }
   ],
   "source": [
    "d1, d2, d3, d4, d5 = [i for i in data.values()] \n",
    "\n",
    "common_keys = []\n",
    "\n",
    "for item in d1.keys():\n",
    "    if item in d2.keys():\n",
    "        if item in d3.keys():\n",
    "            if item in d4.keys():\n",
    "                if item in d5.keys():\n",
    "                    common_keys.append(item)\n",
    "\n",
    "tv = [data[common_keys][\"type\"] for common_keys in data]\n",
    "tiv = [data[common_keys][\"title\"] for common_keys in data]\n",
    "av = [data[common_keys][\"author\"] for common_keys in data]\n",
    "yv = [data[common_keys][\"year\"] for common_keys in data]\n",
    "\n",
    "common_data ={\"entry name\":[i for i in data.keys()], \"type\":tv, \"title\":tiv, \"author\":av, \"year\":yv}\n",
    "print(common_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create the new dictionary with common data for a specific data type**\n",
    "\n",
    "Using a user-defined function `find_common_data()`, your output should look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcdat():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entry name': ['cao2017modelling', 'ishwaran2011consistency', 'FanLv2008sure'], 'type': ['article', 'article', 'article'], 'title': ['Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'Consistency of spike and slab regression', 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.'], 'author': ['Cao, Zheng and Li, Gang and Song, Haiyan', 'Ishwaran, Hemant and Rao, J Sunil', 'Fan, Jianqing and Lv, Jinchi'], 'journal': ['Annals of Tourism Research', 'Statistics \\\\& Probability Letters', 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)'], 'volume': [67, 81, 70], 'pages': ['1--13', '1920--1928', 849], 'year': [2017, 2011, 2008]}\n"
     ]
    }
   ],
   "source": [
    "print(find_common_data('article'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entry name': ['mccullagh2019generalized', 'friedman2001elements'], 'type': ['book', 'book'], 'title': ['Generalized linear models', 'The elements of statistical learning'], 'author': ['McCullagh, Peter and Nelder, John A', 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert'], 'year': [1983, 2001], 'publisher': ['Routledge', 'Springer series in statistics New York']}\n"
     ]
    }
   ],
   "source": [
    "print(find_common_data('book'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'book', 'title': 'Generalized linear models', 'author': 'McCullagh, Peter and Nelder, John A', 'year': 1983, 'publisher': 'Routledge'}\n",
      "{'type': 'book', 'title': 'The elements of statistical learning', 'author': 'Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert', 'volume': 1, 'number': 10, 'year': 2001, 'publisher': 'Springer series in statistics New York'}\n",
      "\n",
      "\n",
      "{'type': 'article', 'title': 'Modelling the interdependence of tourism demand: The global vector autoregressive approach', 'author': 'Cao, Zheng and Li, Gang and Song, Haiyan', 'journal': 'Annals of Tourism Research', 'volume': 67, 'pages': '1--13', 'year': 2017, 'publisher': 'Elsevier'}\n",
      "{'type': 'article', 'author': 'Ishwaran, Hemant and Rao, J Sunil', 'date-added': '2019-09-05 21:53:03 +0200', 'date-modified': '2019-09-05 21:53:14 +0200', 'journal': 'Statistics \\\\& Probability Letters', 'keywords': ['spike-and-slab', 'shrinkage', 'regularization'], 'number': 12, 'pages': '1920--1928', 'publisher': 'Elsevier', 'title': 'Consistency of spike and slab regression', 'volume': 81, 'year': 2011}\n",
      "{'type': 'article', 'author': 'Fan, Jianqing and Lv, Jinchi', 'journal': 'Journal of the Royal Statistical Society. Series B (Statistical Methodology)', 'keywords': ['Adaptive lasso', 'Dantzig selector', 'Dimensionality reduction', 'Oracle estimator', 'Sure independence screening'], 'number': 5, 'pages': 849, 'title': 'Sure Independence Screening for Ultrahigh Dimensional Feature Space.', 'volume': 70, 'year': 2008}\n"
     ]
    }
   ],
   "source": [
    "def find_common_data(value):\n",
    "  \n",
    "    for i in data:\n",
    "        if value == 'article':\n",
    "            if data[i][\"type\"]==value:\n",
    "                print(data[i])\n",
    "        elif value == 'book':\n",
    "            if data[i][\"type\"]==value:\n",
    "                print(data[i])\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "find_common_data(\"book\")\n",
    "print('\\n')\n",
    "find_common_data(\"article\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
